# ìŒì‹ì  ë¦¬ë·° ê°ì„±ë¶„ì„ ëª¨ë¸ êµ¬ì¶• ê³¼ì • ë° ê²°ê³¼ ë¦¬í¬íŠ¸
ìŒì‹ì  ë¦¬ë·° ê°ì„±ë¶„ì„ ëª¨ë¸ êµ¬ì¶•, LSTM, beomi/KcELECTRA-base-v2022 ë¹„êµ

## ê°ì„±ë¶„ì„ ëª¨ë¸ í•™ìŠµ ê³„ê¸°


## ë°ì´í„° ì¤€ë¹„

### [ë¦¬ë·° ë°ì´í„° í¬ë¡¤ë§](https://github.com/tpdus751/naver_map_restaurant_review_crawl_process) 

### ë¦¬ë·° ë°ì´í„° ë¼ë²¨ë§
#### LM Studio API ê°ì •ë¶„ì„ ìš”ì²­ (Gemma 3 12B)
#### í”„ë¡¬í”„íŠ¸ êµ¬ì„±
```python
# âœ… ê°ì • ë¶„ì„ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
def make_batch_prompt(reviews):
    prompt = (
        "ë‹¹ì‹ ì€ ìŒì‹ì  ë¦¬ë·° ê°ì„± ë¶„ì„ê°€ ì…ë‹ˆë‹¤. ë‹¤ìŒ ë¦¬ë·° ëª©ë¡ì„ í™•ì¸í•˜ê³ , ê° ë¦¬ë·°ì˜ ê°ì„±ì„ ìˆ«ìë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.\n"
        "- ë¶€ì •: 0\n- ì¤‘ë¦½: 1\n- ê¸ì •: 2\n"
        "í˜•ì‹: ìˆ«ìë§Œ ì‰¼í‘œë¡œ ë‚˜ì—´, ê¼­ ë¶€ì • 0, ì¤‘ë¦½ 1, ê¸ì • 2ë¥¼ ì§€í‚¬ ê²ƒ. ì˜ˆ: 2,1,0,2,1\n\n"
    )
    for i, review in enumerate(reviews, start=1):
        prompt += f"{i}. {str(review).strip()}\n"
    prompt += "\në‹µ:"
    return prompt

# âœ… ì‘ë‹µ íŒŒì‹±
def parse_response(text, expected_length):
    try:
        values = [int(x.strip()) if x.strip().isdigit() else None for x in text.strip().split(',')]
        if len(values) < expected_length:
            values += [None] * (expected_length - len(values))
        elif len(values) > expected_length:
            values = values[:expected_length]
        return values
    except Exception as e:
        print(f"âš ï¸ ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜: {e}")
        return [None] * expected_length

# âœ… LM Studioë¡œ ê°ì • ë¶„ë¥˜ ìš”ì²­
def classify_batch_lmstudio(reviews):
    prompt = make_batch_prompt(reviews)
    try:
        response = requests.post(LM_STUDIO_API_URL, json={
            "prompt": prompt,
            "max_tokens": 200,
            "temperature": 0.0,
            "stop": ["\n"]
        })

        # âœ… ì‘ë‹µ ìƒíƒœ ì½”ë“œ í™•ì¸
        if response.status_code != 200:
            print(f"ğŸš« ì‘ë‹µ ì‹¤íŒ¨: HTTP {response.status_code}")
            print("ğŸ“© ì‘ë‹µ ë³¸ë¬¸:", response.text)
            return [None] * len(reviews)

        result = response.json()

        # âœ… ì‘ë‹µ êµ¬ì¡° í™•ì¸
        if "choices" not in result:
            print("ğŸš« ì‘ë‹µì— 'choices' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            print("ğŸ“© ì „ì²´ ì‘ë‹µ:", result)
            return [None] * len(reviews)

        response_text = result['choices'][0]['text'].strip()
        print("ğŸ§¾ ì‘ë‹µ:", response_text[:100] + "...")

        return parse_response(response_text, len(reviews))

    except Exception as e:
        print(f"ğŸš« ìš”ì²­ ì‹¤íŒ¨: {e}")
        return [None] * len(reviews)
```

## ëª¨ë¸ ë¹„êµ (LSTM vs beomi/KcELECTRA-base-v2022)

### LSTM
#### ì½”ë“œ
```python
import pandas as pd
import numpy as np
import re
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
```
ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜

```python
df = pd.read_csv('___.csv')  # 'text', 'label' ì»¬ëŸ¼ í¬í•¨
```
csv ë¶ˆëŸ¬ì˜¤ê¸°

```python
df = df.dropna()
```
ê²°ì¸¡ì¹˜ ì œê±°

```python
# ì „ì²˜ë¦¬
def clean_text(text):
    text = re.sub(r'[^\w\s]', '', text)  # íŠ¹ìˆ˜ë¬¸ì ì œê±°
    text = re.sub(r'\d+', '', text)      # ìˆ«ì ì œê±°
    return text.lower().strip()          # ì†Œë¬¸ì + ê³µë°± ì œê±°

# í…ìŠ¤íŠ¸, ë¼ë²¨ ë¶„ë¦¬
X = df['content'].astype(str).apply(clean_text)
y = df['label']
```
ì „ì²˜ë¦¬ ë° text, label ë¶„ë¦¬

```python
print("ë¼ë²¨ ë¶„í¬:\n", y.value_counts())
```
![image](https://github.com/user-attachments/assets/1b8d36a7-482b-403f-a68a-646811afaff8)
ë¼ë²¨ ë¶„í¬ í™•ì¸

```python
# ë¼ë²¨ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„°í”„ë ˆì„ ë‚˜ëˆ„ê¸°
df_0 = df[df['label'] == 0]
df_1 = df[df['label'] == 1].sample(n=20871, random_state=42)
df_2 = df[df['label'] == 2].sample(n=20871, random_state=42)

# ì„¸ í´ë˜ìŠ¤ í•©ì¹˜ê¸°
df_balanced = pd.concat([df_0, df_1, df_2]).sample(frac=1, random_state=42).reset_index(drop=True)

# ë¼ë²¨ ë¶„í¬ í™•ì¸
print("ê· í˜• ë§ì¶˜ ë¼ë²¨ ë¶„í¬:\n", df_balanced['label'].value_counts())
```
![image](https://github.com/user-attachments/assets/cbc565fc-69bb-4076-b14d-d7fb87eb08d3)
ë¼ë²¨ ìˆ˜ê°€ ì ì€ ë¶€ì •ì„ ê¸°ì¤€ìœ¼ë¡œ ê°¯ìˆ˜ í†µì¼

```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
```
í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„ë¦¬

```python
tokenizer = Tokenizer(num_words=10000, oov_token="<OOV>")
tokenizer.fit_on_texts(X_train)

X_train_seq = tokenizer.texts_to_sequences(X_train)
X_test_seq = tokenizer.texts_to_sequences(X_test)
```
í† í¬ë‚˜ì´ì € ë¡œë“œ ë° ì…ë ¥ ë°ì´í„° ì •ìˆ˜ ì¸ì½”ë”©

### KcELECTRA-base-v2022
